{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arijitmazumdar/colab-repo/blob/main/website_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrvsEnQTyQC8"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "UxnxBh_PxVk7"
      },
      "outputs": [],
      "source": [
        "!pip install aiofiles\n",
        "!pip install aiohappyeyeballs\n",
        "!pip install aiohttp\n",
        "!pip install aiosignal\n",
        "!pip install altair\n",
        "!pip install annotated-types\n",
        "!pip install annoy\n",
        "!pip install anthropic\n",
        "!pip install anyio\n",
        "!pip install appdirs\n",
        "!pip install attrs\n",
        "!pip install audioread\n",
        "!pip install beautifulsoup4\n",
        "!pip install blinker\n",
        "!pip install cachetools\n",
        "!pip install certifi\n",
        "!pip install cffi\n",
        "!pip install charset-normalizer\n",
        "!pip install click\n",
        "!pip install contourpy\n",
        "!pip install cryptography\n",
        "!pip install cycler\n",
        "!pip install dataclasses-json\n",
        "!pip install datasets\n",
        "!pip install decorator\n",
        "!pip install defusedxml\n",
        "!pip install dill\n",
        "!pip install distro\n",
        "!pip install faiss-cpu\n",
        "!pip install fastapi\n",
        "!pip install ffmpy\n",
        "!pip install filelock\n",
        "!pip install fonttools\n",
        "!pip install frozenlist\n",
        "!pip install fsspec\n",
        "!pip install gensim\n",
        "!pip install gitdb\n",
        "!pip install GitPython\n",
        "!pip install gradio\n",
        "!pip install gradio_client\n",
        "!pip install h11\n",
        "!pip install httpcore\n",
        "!pip install httpx\n",
        "!pip install huggingface-hub\n",
        "!pip install idna\n",
        "!pip install importlib_resources\n",
        "!pip install Jinja2\n",
        "!pip install jiter\n",
        "!pip install joblib\n",
        "!pip install jsonpatch\n",
        "!pip install jsonpointer\n",
        "!pip install jsonschema\n",
        "!pip install jsonschema-specifications\n",
        "!pip install kiwisolver\n",
        "!pip install langchain\n",
        "!pip install langchain-anthropic\n",
        "!pip install langchain-community\n",
        "!pip install langchain-core\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-google-genai\n",
        "!pip install langchain-text-splitters\n",
        "!pip install langsmith\n",
        "!pip install lazy_loader\n",
        "!pip install librosa\n",
        "!pip install llvmlite\n",
        "!pip install lxml\n",
        "!pip install markdown-it-py\n",
        "!pip install MarkupSafe\n",
        "!pip install marshmallow\n",
        "!pip install matplotlib\n",
        "!pip install mdurl\n",
        "!pip install mpmath\n",
        "!pip install msgpack\n",
        "!pip install multidict\n",
        "!pip install multiprocess\n",
        "!pip install mypy-extensions\n",
        "!pip install narwhals\n",
        "!pip install nest-asyncio\n",
        "!pip install networkx\n",
        "!pip install node2vec\n",
        "!pip install numba\n",
        "!pip install numpy\n",
        "!pip install openai\n",
        "!pip install orjson\n",
        "!pip install packaging\n",
        "!pip install pandas\n",
        "!pip install pdfminer.six\n",
        "!pip install pdfplumber\n",
        "!pip install pillow\n",
        "!pip install pinecone\n",
        "!pip install pinecone-plugin-inference\n",
        "!pip install pinecone-plugin-interface\n",
        "!pip install platformdirs\n",
        "!pip install pooch\n",
        "!pip install protobuf\n",
        "!pip install pyarrow\n",
        "!pip install pycparser\n",
        "!pip install pydantic\n",
        "!pip install pydantic-settings\n",
        "!pip install pydantic_core\n",
        "!pip install pydeck\n",
        "!pip install pydub\n",
        "!pip install Pygments\n",
        "!pip install pyparsing\n",
        "!pip install PyPDF2\n",
        "!pip install pypdfium2\n",
        "!pip install pysbd\n",
        "!pip install python-dateutil\n",
        "!pip install python-dotenv\n",
        "!pip install python-multipart\n",
        "!pip install pytz\n",
        "!pip install PyYAML\n",
        "!pip install ragas\n",
        "!pip install referencing\n",
        "!pip install regex\n",
        "!pip install requests\n",
        "!pip install rich\n",
        "!pip install rpds-py\n",
        "!pip install ruff\n",
        "!pip install safetensors\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install semantic-version\n",
        "!pip install sentence-transformers\n",
        "!pip install shellingham\n",
        "!pip install six\n",
        "!pip install smart-open\n",
        "!pip install smmap\n",
        "!pip install sniffio\n",
        "!pip install soundfile\n",
        "!pip install soupsieve\n",
        "!pip install soxr\n",
        "!pip install SQLAlchemy\n",
        "!pip install starlette\n",
        "!pip install streamlit\n",
        "!pip install sympy\n",
        "!pip install tabulate\n",
        "!pip install tenacity\n",
        "!pip install threadpoolctl\n",
        "!pip install tiktoken\n",
        "!pip install tokenizers\n",
        "!pip install toml\n",
        "!pip install tomlkit\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tornado\n",
        "!pip install tqdm\n",
        "!pip install transformers\n",
        "!pip install typer\n",
        "!pip install typing-inspect\n",
        "!pip install typing_extensions\n",
        "!pip install tzdata\n",
        "!pip install urllib3\n",
        "!pip install uvicorn\n",
        "!pip install websockets\n",
        "!pip install wrapt\n",
        "!pip install xxhash\n",
        "!pip install yarl\n",
        "!pip install fitz\n",
        "!pip install pytesseract\n",
        "!pip install pymupdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hga73LRynDp"
      },
      "source": [
        "Add import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoesSiX817-c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import tempfile\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN8oGYAc2EMO"
      },
      "source": [
        "Pull Open API Key from secret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F7t681p2ILP"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('open_api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRRNi1Dy2i0R"
      },
      "source": [
        "Configuration variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QDOCHxz2lxX"
      },
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 300\n",
        "CHUNK_OVERLAP = 50\n",
        "MAX_TOKENS = 15000\n",
        "MODEL_NAME = \"gpt-4o-mini\"\n",
        "TEMPERATURE = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLUn0rYc2p3c"
      },
      "source": [
        "Functions for cleanly fetch html content from website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhv5wOwr3Dk8"
      },
      "outputs": [],
      "source": [
        "def scrape_website(url):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Remove script and style elements\n",
        "        for script in soup([\"script\", \"style\"]):\n",
        "            script.decompose()\n",
        "\n",
        "        # Get text from various elements\n",
        "        content = []\n",
        "        for elem in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li', 'span', 'div']):\n",
        "            if elem.text.strip():\n",
        "                content.append(elem.text.strip())\n",
        "\n",
        "        # If no content found, try to get all text from body\n",
        "        if not content:\n",
        "            body = soup.find('body')\n",
        "            if body:\n",
        "                content = [body.get_text(separator='\\n', strip=True)]\n",
        "\n",
        "        if not content:\n",
        "            print(\"Warning: No content found. The website might have unusual structure or require JavaScript.\")\n",
        "            return []\n",
        "\n",
        "        return content\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error scraping the website: {e}\")\n",
        "        return []\n",
        "\n",
        "def clean_content(content_list):\n",
        "    # Remove very short or common unwanted items\n",
        "    cleaned = [text for text in content_list if len(text) > 20 and not any(item in text.lower() for item in ['sign up', 'sign in', 'cookie', 'privacy policy'])]\n",
        "    return cleaned\n",
        "\n",
        "def fetch_html(url):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching the website: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_website(url):\n",
        "    html_content = fetch_html(url)\n",
        "    if not html_content:\n",
        "        raise ValueError(\"No content could be fetched from the website.\")\n",
        "\n",
        "    # Use a temporary file to store the HTML content\n",
        "    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html') as temp_file:\n",
        "        temp_file.write(html_content)\n",
        "        temp_file_path = temp_file.name\n",
        "\n",
        "    try:\n",
        "        # Try to use BSHTMLLoader with default settings (which uses 'lxml')\n",
        "        loader = BSHTMLLoader(temp_file_path)\n",
        "        documents = loader.load()\n",
        "    except ImportError:\n",
        "        print(\"'lxml' is not installed. Falling back to built-in 'html.parser'.\")\n",
        "        # If 'lxml' is not available, use the built-in 'html.parser'\n",
        "        loader = BSHTMLLoader(temp_file_path, bs_kwargs={'features': 'html.parser'})\n",
        "        documents = loader.load()\n",
        "\n",
        "    # Clean up the temporary file\n",
        "    os.unlink(temp_file_path)\n",
        "\n",
        "    print(f\"\\nNumber of documents loaded: {len(documents)}\")\n",
        "    if documents:\n",
        "        print(\"Sample of loaded content:\")\n",
        "        print(documents[0].page_content[:200] + \"...\")\n",
        "        print(f\"Metadata: {documents[0].metadata}\")\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    print(f\"Number of text chunks after splitting: {len(texts)}\")\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8XlS1vI3Lou"
      },
      "source": [
        "Utility method to print embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eueTfrT43HZf"
      },
      "outputs": [],
      "source": [
        "def print_sample_embeddings(texts, embeddings):\n",
        "    if texts:\n",
        "        sample_text = texts[0].page_content\n",
        "        sample_embedding = embeddings.embed_query(sample_text)\n",
        "        print(\"\\nSample Text:\")\n",
        "        print(sample_text[:200] + \"...\" if len(sample_text) > 200 else sample_text)\n",
        "        print(\"\\nSample Embedding (first 10 dimensions):\")\n",
        "        print(np.array(sample_embedding[:10]))\n",
        "        print(f\"\\nEmbedding shape: {np.array(sample_embedding).shape}\")\n",
        "    else:\n",
        "        print(\"No texts available for embedding sample.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFLckv1i5id_"
      },
      "source": [
        "Configure LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sashD8Fg5lFe"
      },
      "outputs": [],
      "source": [
        "# #Set up OpenAI language model\n",
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(\n",
        "#     model_name=MODEL_NAME,\n",
        "#     temperature=TEMPERATURE,\n",
        "#     max_tokens=MAX_TOKENS\n",
        "# )\n",
        "\n",
        "# Configuration variables\n",
        "TEMPERATURE = 0.4\n",
        "\n",
        "# Set up Google Gemini language model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=TEMPERATURE, google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "# Set up the retrieval-based QA system with a simplified prompt template\n",
        "template = \"\"\"Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer the question concisely based only on the given context. If the context doesn't contain relevant information, say \"I don't have enough information to answer that question.\"\n",
        "\n",
        "But, if the question is generic, then go ahead and answer the question, example what is a electric vehicle?\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "PROMPT = PromptTemplate(\n",
        "    template=template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# # Set up Ollama language model\n",
        "# from langchain_community.llms import Ollama\n",
        "# llm = Ollama(model=\"tinyllama:latest\", temperature=TEMPERATURE, num_predict=MAX_TOKENS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plHQ_JQF55gM"
      },
      "source": [
        "Setup RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhAaoOlW6DCD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def rag_pipeline(query, qa_chain, vectorstore):\n",
        "    relevant_docs = vectorstore.similarity_search_with_score(query, k=3)\n",
        "\n",
        "    print(\"\\nTop 3 most relevant chunks:\")\n",
        "    context = \"\"\n",
        "    for i, (doc, score) in enumerate(relevant_docs, 1):\n",
        "        print(f\"{i}. Relevance Score: {score:.4f}\")\n",
        "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
        "        print()\n",
        "        context += doc.page_content + \"\\n\\n\"\n",
        "\n",
        "    # Print the full prompt\n",
        "    full_prompt = PROMPT.format(context=context, question=query)\n",
        "    print(\"\\nFull Prompt sent to the model:\")\n",
        "    print(full_prompt)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "    response = qa_chain.invoke({\"query\": query})\n",
        "    return response['result']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccwlijby6F9f"
      },
      "source": [
        "Setup main method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxu8j93T6I5t"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Welcome to the Enhanced Web Scraping RAG Pipeline.\")\n",
        "\n",
        "    while True:\n",
        "        url = input(\"Please enter the URL of the website you want to query (or 'quit' to exit): \")\n",
        "        if url.lower() == 'quit':\n",
        "            print(\"Exiting the program. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            print(\"Processing website content...\")\n",
        "            texts = process_website(url)\n",
        "\n",
        "            if not texts:\n",
        "                print(\"No content found on the website. Please try a different URL.\")\n",
        "                continue\n",
        "\n",
        "            print(\"Creating embeddings and vector store...\")\n",
        "            from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "            embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "\n",
        "            print_sample_embeddings(texts, embeddings)\n",
        "\n",
        "            vectorstore = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "            qa = RetrievalQA.from_chain_type(\n",
        "                llm=llm,\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=vectorstore.as_retriever(),\n",
        "                memory = memory,\n",
        "                chain_type_kwargs={\"prompt\": PROMPT}\n",
        "            )\n",
        "\n",
        "            print(\"\\nRAG Pipeline initialized. You can now enter your queries.\")\n",
        "            print(\"Enter 'new' to query a new website or 'quit' to exit the program.\")\n",
        "\n",
        "            while True:\n",
        "                user_query = input(\"\\nEnter your query: \")\n",
        "                if user_query.lower() == 'quit':\n",
        "                    print(\"Exiting the program. Goodbye!\")\n",
        "                    exit()\n",
        "                elif user_query.lower() == 'new':\n",
        "                    break\n",
        "\n",
        "                result = rag_pipeline(user_query, qa, vectorstore)\n",
        "                print(f\"RAG Response: {result}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            print(\"Please try a different URL or check your internet connection.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPisK0szCZn/FrYjtwrnKi5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}