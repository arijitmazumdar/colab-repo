{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTei1MevOXEY1/e652XJ9c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arijitmazumdar/colab-repo/blob/main/duckdb_arrow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-wVx1AqpSCY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f39cd78"
      },
      "source": [
        "# Task\n",
        "Create a sample Python program that loads a CSV file using DuckDB, converts the data to Apache Arrow format, and stores it in a SQLite database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bacbfbc8"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries (duckdb, pyarrow, pandas, sqlite3).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5efb45e"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries using pip. SQLite3 is usually included in Python's standard library, so we don't need to install it separately via pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d44aee89",
        "outputId": "daf714ad-c4c9-46b8-ab72-acfc212b57d8"
      },
      "source": [
        "%pip install duckdb pyarrow pandas"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedeba0e"
      },
      "source": [
        "## Create sample csv\n",
        "\n",
        "### Subtask:\n",
        "Create a dummy CSV file for testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa937739"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a pandas DataFrame with sample data and save it to a CSV file as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53881d09",
        "outputId": "6a8c656b-a966-4ae1-bcfd-6318de6c14af"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "data = {\n",
        "    'integer_col': [1, 2, 3, 4, 5],\n",
        "    'string_col': ['apple', 'banana', 'cherry', 'date', 'elderberry'],\n",
        "    'float_col': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
        "    'date_col': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'])\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file without the index\n",
        "df.to_csv('sample_data.csv', index=False)\n",
        "\n",
        "print(\"Dummy CSV file 'sample_data.csv' created successfully.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy CSV file 'sample_data.csv' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80b7f199"
      },
      "source": [
        "## Load csv with duckdb\n",
        "\n",
        "### Subtask:\n",
        "Use DuckDB to load the data from the created CSV file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee77335d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires loading the data from the created CSV file using DuckDB. This involves importing the `duckdb` library, connecting to a DuckDB database, and executing a SQL query to read the CSV.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ebe39ff",
        "outputId": "7bd986b6-3d02-4ef3-dffe-bf2096a6c054"
      },
      "source": [
        "import duckdb\n",
        "\n",
        "# Connect to an in-memory DuckDB database\n",
        "con = duckdb.connect(database=':memory:', read_only=False)\n",
        "\n",
        "# Execute a SQL query to read the 'sample_data.csv' file\n",
        "duckdb_result = con.execute(\"SELECT * FROM 'sample_data.csv'\").fetchall()\n",
        "\n",
        "# Print the result to verify\n",
        "print(duckdb_result)\n",
        "\n",
        "# Close the connection (optional for in-memory, but good practice)\n",
        "con.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'apple', 1.1, datetime.date(2023, 1, 1)), (2, 'banana', 2.2, datetime.date(2023, 1, 2)), (3, 'cherry', 3.3, datetime.date(2023, 1, 3)), (4, 'date', 4.4, datetime.date(2023, 1, 4)), (5, 'elderberry', 5.5, datetime.date(2023, 1, 5))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fcb583"
      },
      "source": [
        "## Convert to arrow\n",
        "\n",
        "### Subtask:\n",
        "Convert the data loaded by DuckDB into Apache Arrow format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ea07a1"
      },
      "source": [
        "**Reasoning**:\n",
        "Connect to DuckDB, execute a query to read the CSV, fetch the result as an Arrow object, store it, and close the connection as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b89415a",
        "outputId": "32c563ad-82d6-4036-aefe-a42fa41dce23"
      },
      "source": [
        "import duckdb\n",
        "import pyarrow as pa\n",
        "\n",
        "# Connect to an in-memory DuckDB database\n",
        "con = duckdb.connect(database=':memory:', read_only=False)\n",
        "\n",
        "# Execute a SQL query to read the 'sample_data.csv' file and fetch as Arrow\n",
        "arrow_table = con.execute(\"SELECT * FROM 'sample_data.csv'\").arrow()\n",
        "\n",
        "# Store the resulting Arrow object in a variable (already done in the previous step)\n",
        "# Display the Arrow table to verify\n",
        "print(\"Data loaded into Apache Arrow format:\")\n",
        "print(arrow_table)\n",
        "\n",
        "# Close the DuckDB connection\n",
        "con.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into Apache Arrow format:\n",
            "pyarrow.Table\n",
            "integer_col: int64\n",
            "string_col: string\n",
            "float_col: double\n",
            "date_col: date32[day]\n",
            "----\n",
            "integer_col: [[1,2,3,4,5]]\n",
            "string_col: [[\"apple\",\"banana\",\"cherry\",\"date\",\"elderberry\"]]\n",
            "float_col: [[1.1,2.2,3.3,4.4,5.5]]\n",
            "date_col: [[2023-01-01,2023-01-02,2023-01-03,2023-01-04,2023-01-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaeabdb2"
      },
      "source": [
        "## Store in sqlite\n",
        "\n",
        "### Subtask:\n",
        "Store the data from the Arrow format into a SQLite database.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58a018c2"
      },
      "source": [
        "**Reasoning**:\n",
        "Store the data from the Arrow format into a SQLite database following the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2638415f",
        "outputId": "f01c8117-a1c7-406a-a1e2-29cbae6b3c7b"
      },
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to a SQLite database file\n",
        "conn = sqlite3.connect('sample_data.db')\n",
        "\n",
        "# Convert the Arrow Table to a pandas DataFrame\n",
        "df = arrow_table.to_pandas()\n",
        "\n",
        "# Use the .to_sql() method to write the data to a table in the SQLite database\n",
        "df.to_sql('sample_table', conn, if_exists='replace', index=False)\n",
        "\n",
        "# Commit the changes to the database\n",
        "conn.commit()\n",
        "\n",
        "# Close the SQLite database connection\n",
        "conn.close()\n",
        "\n",
        "print(\"Data successfully stored in 'sample_data.db' in table 'sample_table'.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully stored in 'sample_data.db' in table 'sample_table'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a648386a"
      },
      "source": [
        "## Verify data in sqlite\n",
        "\n",
        "### Subtask:\n",
        "Read the data from the SQLite database to verify it was stored correctly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf0b63d6"
      },
      "source": [
        "**Reasoning**:\n",
        "Read the data from the SQLite database to verify it was stored correctly by connecting to the database, selecting all data from the table, and printing the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c84401f",
        "outputId": "4956098d-8c00-4730-d558-36c42c19e5a9"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite database file\n",
        "conn = sqlite3.connect('sample_data.db')\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Execute a SQL query to select all data from the 'sample_table'\n",
        "cursor.execute(\"SELECT * FROM sample_table\")\n",
        "\n",
        "# Fetch all the results\n",
        "results = cursor.fetchall()\n",
        "\n",
        "# Print the fetched data\n",
        "print(\"Data read from SQLite database:\")\n",
        "for row in results:\n",
        "    print(row)\n",
        "\n",
        "# Close the cursor and the database connection\n",
        "cursor.close()\n",
        "conn.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data read from SQLite database:\n",
            "(1, 'apple', 1.1, '2023-01-01')\n",
            "(2, 'banana', 2.2, '2023-01-02')\n",
            "(3, 'cherry', 3.3, '2023-01-03')\n",
            "(4, 'date', 4.4, '2023-01-04')\n",
            "(5, 'elderberry', 5.5, '2023-01-05')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaef6626"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The necessary libraries (duckdb, pyarrow, pandas, and the built-in sqlite3) were available in the environment, allowing the program to proceed.\n",
        "*   A sample CSV file named `sample_data.csv` was successfully created with columns of different data types (integer, string, float, date).\n",
        "*   DuckDB was successfully used to load the data from `sample_data.csv`, and the results were retrieved.\n",
        "*   The data loaded by DuckDB was successfully converted into an Apache Arrow `Table` using the `.arrow()` method.\n",
        "*   The Apache Arrow `Table` was converted to a pandas DataFrame and then successfully stored in a SQLite database file named `sample_data.db` within a table called `sample_table`.\n",
        "*   Verification confirmed that the data was correctly written to the SQLite database by reading it back and printing it.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   This process demonstrates a flexible way to move data between different storage formats and tools (CSV -> DuckDB -> Arrow -> SQLite), which can be useful in various data pipelines.\n",
        "*   The use of Apache Arrow as an intermediate format can be beneficial for performance when dealing with larger datasets or integrating with other Arrow-compatible systems.\n"
      ]
    }
  ]
}